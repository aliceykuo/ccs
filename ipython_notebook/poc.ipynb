{
 "metadata": {
  "name": "",
  "signature": "sha256:11395c1766607cfd2a8813c3a43221ed0629b91e165140f1c9fca8610d932593"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage import io\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from skimage.color import rgb2gray\n",
      "# from skimage.exposure import \n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from PIL import Image\n",
      "import cv2\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#setup a standard image size - downsize and get all images to the same dimensions \n",
      "#converts into a numpy array of RGB pixels\n",
      "\n",
      "standard_size = (100, 75)\n",
      "def img_to_matrix(filename):\n",
      "    img = Image.open(filename)\n",
      "    img = img.resize(standard_size)\n",
      "    img = list(img.getdata())\n",
      "    img = map(list, img)\n",
      "    img = np.array(img)\n",
      "    return img\n",
      " \n",
      "def flatten_image(img):\n",
      "    img =img.ravel() \n",
      "    return img"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# matrix t\n",
      "img = img_to_matrix('beach/beach1.jpg')\n",
      "print img\n",
      "print (flatten_image(img))\n",
      "print \"length:\", len(flatten_image(img))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 98  87 103]\n",
        " [ 90  92 115]\n",
        " [ 75  92 122]\n",
        " ..., \n",
        " [ 48  40  38]\n",
        " [ 50  42  40]\n",
        " [ 50  42  40]]\n",
        "[ 98  87 103 ...,  50  42  40]\n",
        "length: 22500\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def process(label, n):\n",
      "    beach = []\n",
      "    for i in range(1,n):\n",
      "        img_url = label + '/' + label\n",
      "        img = img_to_matrix(img_url + str(i) + '.jpg')\n",
      "        beach.append(flatten_image(img))\n",
      "    print beach\n",
      "#     print \"length:\", len(flatten_image(img))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "process('beach', 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[array([ 98,  87, 103, ...,  50,  42,  40]), array([249, 240, 199, ..., 255, 251, 235]), array([236, 220, 194, ..., 124, 172, 174]), array([ 22,  21,  16, ..., 153, 126, 105])]\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# img_dir = \"images\"\n",
      "# images = [img_dir+ f for f in os.listdir(img_dir)]\n",
      "# labels = [\"beach\" if \"beach\" in f.split('/')[-1] else \"rustic\" for f in images]\n",
      " \n",
      "# data = []\n",
      "# for image in images:\n",
      "#     img = img_to_matrix(image)\n",
      "#     img = flatten_image(img)\n",
      "#     data.append(img)\n",
      " \n",
      "# data = np.array(data)\n",
      "# data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# img = cv2.imread('beach1.jpg')\n",
      "# mask = np.zeros(img.shape[:2],np.uint8)\n",
      "\n",
      "# bgdModel = np.zeros((1,65),np.float64)\n",
      "# fgdModel = np.zeros((1,65),np.float64)\n",
      "\n",
      "# rect = (50,50,450,290)\n",
      "# cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
      "\n",
      "# mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
      "# img = img*mask2[:,:,np.newaxis]\n",
      "\n",
      "# plt.imshow(img),plt.colorbar(),plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#source https://gist.github.com/daien/1989208\n",
      "class MLR(object):\n",
      "    \"\"\" Multinomial Logistic Regression classifier\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    sigma2: float, optional, default: None,\n",
      "            Bandwidth of Gaussian prior for MAP estimation\n",
      "            (penalization parameter)\n",
      "\n",
      "    weighted: boolean, optional, default: False,\n",
      "              if False, then maximize sum_n log sum_c labels(n,c) p(c|data_n)\n",
      "              if True, then maximize sum_n sum_c labels(n,c) log p(c|data_n)\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    W_ : numpy array, shape [n_features, n_classes],\n",
      "         the coefficient estimates \n",
      "\n",
      "    infos_ : dict,\n",
      "             various output infos about the optimization\n",
      "    \"\"\"\n",
      "    def __init__(self, ss=None, weighted=False, seed=None):\n",
      "        assert ss is None or ss > 0, \"ss must be None or > 0\"\n",
      "        self.ss = ss\n",
      "        self.weighted = weighted\n",
      "        self.seed = seed\n",
      "        self.W_ = None\n",
      "        self.nll_ = None\n",
      "        self.grad_ = None\n",
      " \n",
      "    def fit(self, X, y):\n",
      "        \"\"\" Fit the model\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like, shape [n_samples, n_features],\n",
      "            Training data\n",
      "\n",
      "        y : array-like, shape [n_samples] or [n_samples, n_classes]\n",
      "            Target values\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self : returns an instance of self.\n",
      "        \"\"\"\n",
      "        n_samples, n_features = X.shape\n",
      " \n",
      "        # get the target values\n",
      "        if y.ndim == 1:\n",
      "            # convert to 1-of-k coding (one-hot)\n",
      "            assert len(y) == n_samples, \"Invalid number of labels\"\n",
      "            self.classes = np.unique(y)\n",
      "            n_classes = len(self.classes)\n",
      "            Y = np.zeros((n_samples, n_classes), dtype=np.float64)\n",
      "            for i, cls in enumerate(self.classes):\n",
      "                Y[y == cls, i] = 1\n",
      "        else:\n",
      "            _n, n_classes = Y.shape\n",
      "            assert _n == n_samples, \"Invalid number of rows in Y\"\n",
      "            self.classes = np.arange(n_classes)\n",
      "            Y = y\n",
      " \n",
      "        # initialize the weight matrix\n",
      "        np.random.seed(self.seed)\n",
      "        w0 = np.random.random((n_features * n_classes, ))\n",
      " \n",
      "        # initialize the functions to compute the cost function and gradient\n",
      "        fgcomp = FuncGradComputer(X, Y, self.ss, self.weighted)\n",
      "        fun = fgcomp.compute_fun\n",
      "        grad = fgcomp.compute_grad\n",
      " \n",
      "        # minimize with BFGS\n",
      "        results = fmin_bfgs(fun, w0, fprime=grad, full_output=True)\n",
      "        self.W_ = results[0].reshape((n_features, n_classes))\n",
      "        self.infos_ = dict(zip(\n",
      "            \"fopt gopt Bopt func_calls grad_calls warnflat\".split(),\n",
      "            results[1:]))\n",
      " \n",
      "        return self\n",
      " \n",
      " \n",
      "    def predict_proba(self, X):\n",
      "        \"\"\" Probability estimates.\n",
      "\n",
      "        The returned estimates for all classes, ordered by label.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like, shape = [n_samples, n_features]\n",
      "            Vectors to predict\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        Yhat : array-like, shape = [n_samples, n_classes]\n",
      "               Probability of the sample for each class in the model,\n",
      "               where classes are ordered by arithmetical order.\n",
      "        \"\"\"\n",
      "        Yhat = np.dot(X, self.W_)\n",
      "        Yhat -= Yhat.min(axis=1)[:, np.newaxis]\n",
      "        Yhat = np.exp(-Yhat)\n",
      "        # l1-normalize\n",
      "        Yhat /= Yhat.sum(axis=1)[:, np.newaxis]\n",
      "        return Yhat\n",
      " \n",
      " \n",
      "    def predict(self, X):\n",
      "        \"\"\" Predict most likely label\n",
      "\n",
      "        The returned estimates for all classes, ordered by label.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like, shape = [n_samples, n_features]\n",
      "            Vectors to predict\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        yhat : array-like, shape = [n_samples]\n",
      "               The most likely label for each sample.\n",
      "        \"\"\"\n",
      "        Yhat = self.predict_proba(X)\n",
      "        yhat = self.classes[np.argmax(Yhat, axis=1).squeeze()]\n",
      "        return yhat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> from sklearn import datasets\n",
      ">>> from sklearn.multiclass import OneVsOneClassifier\n",
      ">>> from sklearn.svm import LinearSVC\n",
      ">>> iris = datasets.load_iris()\n",
      ">>> X, y = iris.data, iris.target\n",
      ">>> OneVsOneClassifier(LinearSVC(random_state=0)).fit(X, y).predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    train_feat, test_feat, train_target, test_target = train_test_split(feature_arr, target_arr, test_size=0.33)\n",
      "    rf = RandomForestClassifier()\n",
      "    rf.fit(train_feat, train_target)\n",
      "    print rf.score(test_feat, test_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}